{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191deaa6",
   "metadata": {},
   "source": [
    "# Import Libraries, Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf6d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Create the nlp object\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# increase the amount of text to display\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71ba393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "tales = pd.read_csv('../data/tales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783abf66",
   "metadata": {},
   "source": [
    "---\n",
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c214406",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop missing values in 'selftext' ##\n",
    "tales.dropna(inplace = True)\n",
    "\n",
    "## drop columns ##\n",
    "drop_cols = ['created_utc', 'author', 'score', 'is_self']\n",
    "tales.drop(columns = drop_cols, inplace = True)\n",
    "\n",
    "## convert timestamp to datetime ##\n",
    "tales['timestamp'] = pd.to_datetime(tales['timestamp'])\n",
    "\n",
    "## drop ['deleted'] from 'selftext' ##\n",
    "tales.drop(tales[tales['selftext'] == '[deleted]'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7649e06",
   "metadata": {},
   "source": [
    "---\n",
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21da7095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word count for each document\n",
    "def word_count(string):\n",
    "    words = string.split()\n",
    "    return len(words)\n",
    "\n",
    "# average word length in doc\n",
    "def avg_word_length(string):\n",
    "    words = string.split()\n",
    "    word_lengths = [len(word) for word in words]\n",
    "    avg_word_length = sum(word_lengths)/len(words)\n",
    "    return(avg_word_length)\n",
    "\n",
    "# create lemmatized, alpha-only text, stopwords removed\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "def spacy_clean(string):\n",
    "    doc = nlp(string)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    lemmas_clean = [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stopwords]\n",
    "    return ' '.join(lemmas_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab1f10",
   "metadata": {},
   "source": [
    "---\n",
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3056c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TITLE_TEXT: minimally processed text data ##\n",
    "\n",
    "# lowercase\n",
    "tales['title_text'] = tales['selftext'].str.lower()\n",
    "\n",
    "# replace youtube links with 'youtube'\n",
    "tales['title_text'] = tales['title_text'].apply(lambda s: ' '.join(re.sub(r'\\S+youtube\\S+', 'youtube', s).split()))\n",
    "\n",
    "# remove links and references to subreddit name in text\n",
    "tales['title_text'] = tales['title_text'].replace('http\\S+', '', regex=True).replace('www\\S+', '', regex=True).replace('tales\\S+', '', regex=True)\n",
    "\n",
    "# combine title with text\n",
    "tales['title_text'] = tales['title'] + \" \\n\" + tales['title_text']\n",
    "\n",
    "## TITLE_TEXT_LEMMA: lemmatized text data\n",
    "# lemmatize text, remove numbers and stopwords\n",
    "tales['title_text_lemma'] = tales['title_text'].apply(spacy_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad210b0b",
   "metadata": {},
   "source": [
    "---\n",
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4809a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELFTEXT: raw text data\n",
    "\n",
    "# raw document length, character count\n",
    "tales['char_length_selftext'] = tales['selftext'].str.len()\n",
    "\n",
    "# raw document word count\n",
    "tales['word_count_selftext'] = tales['selftext'].apply(word_count)\n",
    "\n",
    "# raw document average word length\n",
    "tales['avg_word_length_selftext'] = tales['selftext'].apply(avg_word_length)\n",
    "\n",
    "\n",
    "# TITLE_TEXT: minimally processed text data\n",
    "\n",
    "# document length, character count\n",
    "tales['char_length_title_text'] = tales['title_text'].str.len()\n",
    "\n",
    "# document word count\n",
    "tales['word_count_title_text'] = tales['title_text'].apply(word_count)\n",
    "\n",
    "# average doc word length\n",
    "tales['avg_word_length_title_text'] = tales['title_text'].apply(avg_word_length)\n",
    "\n",
    "\n",
    "# TITLE_TEXT_LEMMA: lemmatized text data\n",
    "\n",
    "# character length based on lemma text column\n",
    "tales['char_length_lemma'] = tales['title_text_lemma'].str.len()\n",
    "\n",
    "# word count based on lemma text column\n",
    "tales['word_count_lemma'] = tales['title_text_lemma'].apply(word_count)\n",
    "\n",
    "# average doc word length\n",
    "tales['avg_word_length_lemma'] = tales['title_text_lemma'].apply(avg_word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f980b741",
   "metadata": {},
   "source": [
    "---\n",
    "# Save data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd8ec539",
   "metadata": {},
   "outputs": [],
   "source": [
    "tales.to_csv('../data/tales_clean.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
